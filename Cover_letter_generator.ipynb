{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rWmdRtbSPjN"
      },
      "outputs": [],
      "source": [
        "pip install langchain_groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq"
      ],
      "metadata": {
        "id": "tm7AWWuISfMc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(\n",
        "    temperature=0,\n",
        "    groq_api_key='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',\n",
        "    model_name=\"llama-3.3-70b-versatile\"\n",
        ")\n",
        "response = llm.invoke(\"The first person to land on moon was ...\")\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WI7Ql8iiSsu6",
        "outputId": "045327cc-381c-4e3b-e947-93fd18f0d265"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first person to land on the moon was Neil Armstrong. He stepped out of the lunar module Eagle and onto the moon's surface on July 20, 1969, during the Apollo 11 mission. Armstrong famously declared, \"That's one small step for man, one giant leap for mankind,\" as he became the first human to set foot on the moon.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Data Scientist/Engineer at Greenspoon Kenya\n",
        "View Jobs in Food Services / View Jobs at Greenspoon KenyaPosted: Jan 3, 2025Deadline: Not specified\n",
        "\n",
        "\n",
        "\n",
        "Greenspoon Kenya is the online store for people who care about what they eat. Founded in September 2016, Greenspoon was born of a desire to support artisan producers in Kenya, and at the same time provide increased transparency to consumers around the provenance of their food. We are proud to be the first online retail store specifically geared towards showc...\n",
        "Read more about this company\n",
        "\n",
        "\n",
        "Data Scientist/EngineerJob TypeFull TimeQualificationBA/BSc/HNDExperience 2 yearsLocationNairobiJob FieldData, Business Analysis and AI  , ICT / Computer\n",
        "As our Data Scientist/Engineer, you'll architect and implement data solutions that power Greenspoon's next phase of growth. You'll work closely with operational teams (e.g. logistics, finance, marketing) to transform our vast data resources into strategic advantages, helping us make smarter decisions about inventory, customer preferences, delivery optimization, and market trends.\n",
        "\n",
        "Key responsibilities\n",
        "\n",
        "Technical leadership:\n",
        "\n",
        "Design and implement scalable data warehouse and data lake architectures\n",
        "Build and maintain ETL pipelines for processing diverse data sources\n",
        "Develop and deploy machine learning models for demand forecasting, logistics optimizations, and customer behavior analysis\n",
        "Create robust data validation and quality assurance processes\n",
        "Implement data governance frameworks and best practices\n",
        "\n",
        "Business impact:\n",
        "\n",
        "Partner with business teams to identify opportunities for data-driven optimization\n",
        "Develop predictive models for inventory management and supply chain efficiency\n",
        "Create dashboards and visualization tools for business intelligence\n",
        "Analyze customer behavior patterns to enhance personalization and service delivery\n",
        "Support data-driven decision making across all departments\n",
        "\n",
        "Development:\n",
        "\n",
        "Build automated reporting systems and self-service analytics tools\n",
        "Develop APIs and interfaces for internal data access\n",
        "Optimize data storage and processing for cost efficiency\n",
        "Required skills & experience\n",
        "\n",
        "Technical expertise:\n",
        "\n",
        "Strong programming skills in Python, SQL, and data processing frameworks\n",
        "Experience with cloud-based data platforms (AWS, Google Cloud, or Azure)\n",
        "Conversant with ETL technologies (e.g. Airbyte, Postman)\n",
        "Proficiency in data warehousing concepts and technologies (e.g. Snowflake, Azure)\n",
        "Expertise in machine learning frameworks and statistical analysis\n",
        "Knowledge of efficiently managing data visualization tools (e.g. PowerBI, Tableau)\n",
        "Experience in automation software (e.g. PowerAutomate, UIPath) is a plus\n",
        "Experience working with D2C ecommerce platforms (Shopify, WooCommerce) is a plus\n",
        "Experience working with ERPs (e.g. Microsoft Dynamics, SAP) is a plus\n",
        "Knowledge of WordPress data structures is a plus\n",
        "\n",
        "Business acumen:\n",
        "\n",
        "Demonstrated ability to translate business requirements into technical solutions\n",
        "Strong project management and stakeholder communication skills\n",
        "Ability to explain complex technical concepts to non-technical audiences\n",
        "Track record of delivering data projects with measurable business impact\n",
        "Background:\n",
        "\n",
        "Degree in computer science, statistics or similar with excellent academic achievement\n",
        "2+ years of experience working with data and algorithms in some sort\n",
        "Analytical mindset combined with business pragmatism\n",
        "Self-directed with strong problem-solving abilities\n",
        "Excellent communication and collaboration skills\n",
        "Adaptable to changing priorities in a fast-paced environment\n",
        "Passion for sustainability and social impact\n",
        "\n",
        "Method of Application\n",
        "Please email us at hr@greenspoon.co.ke with a cover letter clearly indicating your achievements, experience and expertise. Give examples of business problems you have solved, what the impact was and your approach to solving the problem and which challenges you faced. An analytical test will be part of the hiring procedure.\"\"\""
      ],
      "metadata": {
        "id": "jv5VR4yvj1zg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "prompt_extract = PromptTemplate.from_template(\n",
        "        \"\"\"\n",
        "        ### SCRAPED TEXT FROM WEBSITE:\n",
        "        {page_data}\n",
        "        ### INSTRUCTION:\n",
        "        The text is from the career's page of a website.\n",
        "        Your job is to extract the job title and return it in JSON format containing the\n",
        "        following keys: `role`, `experience`, `skills`, 'key responsibilities', and `description`.\n",
        "        Only return the valid JSON.\n",
        "        ### VALID JSON (NO PREAMBLE):\n",
        "        \"\"\"\n",
        ")\n",
        "\n",
        "chain_extract = prompt_extract | llm\n",
        "res = chain_extract.invoke(input={'page_data':text})\n",
        "type(res.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nvupBWCm5sS",
        "outputId": "9fac7f2c-084d-4c17-e204-f4252208ea51"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "\n",
        "json_parser = JsonOutputParser()\n",
        "json_res = json_parser.parse(res.content)\n",
        "json_res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHJL6Lfpshdx",
        "outputId": "83de1390-b836-4aca-d53f-eadb1c786dfd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'role': 'Data Scientist/Engineer',\n",
              " 'experience': '2 years',\n",
              " 'skills': ['Python',\n",
              "  'SQL',\n",
              "  'Data processing frameworks',\n",
              "  'Cloud-based data platforms (AWS, Google Cloud, or Azure)',\n",
              "  'ETL technologies (e.g. Airbyte, Postman)',\n",
              "  'Data warehousing concepts and technologies (e.g. Snowflake, Azure)',\n",
              "  'Machine learning frameworks and statistical analysis',\n",
              "  'Data visualization tools (e.g. PowerBI, Tableau)',\n",
              "  'Automation software (e.g. PowerAutomate, UIPath)',\n",
              "  'D2C ecommerce platforms (Shopify, WooCommerce)',\n",
              "  'ERPs (e.g. Microsoft Dynamics, SAP)',\n",
              "  'WordPress data structures'],\n",
              " 'key responsibilities': ['Technical leadership',\n",
              "  'Business impact',\n",
              "  'Development'],\n",
              " 'description': \"As our Data Scientist/Engineer, you'll architect and implement data solutions that power Greenspoon's next phase of growth. You'll work closely with operational teams (e.g. logistics, finance, marketing) to transform our vast data resources into strategic advantages, helping us make smarter decisions about inventory, customer preferences, delivery optimization, and market trends.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(json_res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5v8AlEQsU_q",
        "outputId": "2961fd63-6148-44ba-d81c-222e31ac29af"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fitz"
      ],
      "metadata": {
        "id": "X7L17wAqyzaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall pymupdf -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6IoJ2aJz2uf",
        "outputId": "74f8656d-7723-4c38-b218-adc25ba2e377"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping pymupdf as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pymupdf --no-cache-dir"
      ],
      "metadata": {
        "id": "Ff7qaY_n0R6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF for PDF parsing"
      ],
      "metadata": {
        "id": "Tz58CKKQywql"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract text from PDF\n",
        "file_path = ''\n",
        "def extract_text_from_pdf(/content/WALTER KIPTANUI ROTICH CV.pdf):\n",
        "    with fitz.open(/content/WALTER KIPTANUI ROTICH CV.pdf) as doc:\n",
        "        text = \"\\n\".join([page.get_text(\"text\") for page in doc])\n",
        "    return text"
      ],
      "metadata": {
        "id": "2Op_MQXCqFpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/WALTER KIPTANUI ROTICH CV.pdf'"
      ],
      "metadata": {
        "id": "K9eLq5AF3b4c"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract text from PDF\n",
        "def extract_text_from_pdf(file_path):\n",
        "    with fitz.open(file_path) as doc:\n",
        "        text = \"\\n\".join([page.get_text(\"text\") for page in doc])\n",
        "    return text"
      ],
      "metadata": {
        "id": "3beoweU33z9C"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "pdf_path = \"/content/WALTER KIPTANUI ROTICH CV.pdf\"\n",
        "pdf_text = extract_text_from_pdf(pdf_path)\n",
        "print(pdf_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyuNQYjq3TJh",
        "outputId": "ae02c463-3d26-4d70-acd7-e595a020044c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WALTER KIPTANUI ROTICH \n",
            "| Python | SQL | Data Science | Machine Learning | Data Visualization | Excel | MySQL | C |C++ | \n",
            "Deep Learning | Model Deployment (Flask, Streamlit, FastAPI, Heroku) | Statistics | Technical \n",
            "Writing | Fundamentals of Cloud Computing |  \n",
            "  \n",
            "Tel: +254 706187593 | Nairobi, Kenya | Email: walterkiptanui5@gmail.com \n",
            "LinkedIn: https://www.linkedin.com/in/walter-kiptanui-15790a224 \n",
            "Github: https://www.github.com/walter-kiptanui \n",
            "Medium: https://medium.com/@walterkiptanui5 \n",
            "Kaggle: https://www.kaggle.com/waltee \n",
            "Zindi: https://zindi.africa/users/waltee \n",
            " \n",
            " \n",
            "PROJECTS \n",
            " \n",
            " Made a project presentation during the Data Science and Artificial Intelligence \n",
            "Conference 2023 held at Kabarak University from 1st to 3rd February 2023. \n",
            "https://conferences.kabarak.ac.ke/index.php/dsai/issue/archive \n",
            " Participated as a competitor and ambassador of the UmojaHackAfrica 2023 Machine \n",
            "Learning challenge on Zindi platform. Bagged position 103/247 in the intermediate \n",
            "challenge. https://github.com/walter-kiptanui/Umoja-Hack-Africa-2023 \n",
            " Data Analysis of children at the Huruma Hospital in Eldoret for a medical \n",
            "practitioner. \n",
            " Worked on a project assigned to me by Center for Epidemiological Modelling and \n",
            "Analysis (CEMA). In the project, my task was to create a model that classifies blood \n",
            "sample images as either infected with malaria or not. I obtained the dataset under \n",
            "the Tensorflow Image libraries. https://github.com/walter-kiptanui/Blood-Smear-\n",
            "classification \n",
            " Created and deployed an NLP bot for performing classification tasks on Toloka \n",
            "platform. The task in question is (Is The Ad a Good Match to the Search Term?). \n",
            "The data labeled had 80% accuracy. https://medium.com/@walterkiptanui5/is-the-ad-\n",
            "a-good-match-taac-task-on-toloka-automated-181277677f22 \n",
            " Predictive analysis of the rooftop solar potential data obtained from a certain area of \n",
            "interest in Nairobi. https://github.com/walter-kiptanui/Rooftop-Solar-Potential-\n",
            "Mapping \n",
            " \n",
            " \n",
            "ACADEMIC QUALIFICATIONS \n",
            " BSc. Electrical and Electronics Engineering, 2nd Class Upper Division  | Kenyatta \n",
            "University | \n",
            " \n",
            "\n",
            "TRAINING & PROFESSIONAL CERTIFICATIONS  \n",
            " Certificate of completion - Advanced Level of the Data Science Mentorship Training \n",
            "| Everything Data | May 2024 | \n",
            " Certificate of Completion – Data Science with Python | National Research Fund \n",
            "(NRF Kenya) | October 2021 |. \n",
            " Skill Badge – Embedded Machine Learning | Coursera | March 2022 \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cover Letter Prompt\n",
        "prompt_cover_letter = PromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    ### RESUME:\n",
        "    {resume_text}\n",
        "\n",
        "    ### JOB DESCRIPTION:\n",
        "    {job_data}\n",
        "\n",
        "    ### TASK:\n",
        "    Write a compelling, personalized cover letter tailored for the job.\n",
        "    The letter should:\n",
        "    - Start with a strong introduction that grabs attention.\n",
        "    - Highlight my most relevant skills and experience.\n",
        "    - Clearly explain why I am a perfect fit for the role.\n",
        "    - End with a professional call-to-action.\n",
        "\n",
        "    ### COVER LETTER:\n",
        "    \"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "tGqqJsrt48ob"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create LangChain pipeline\n",
        "chain_cover_letter = prompt_cover_letter | llm\n",
        "\n",
        "# Generate Cover Letter\n",
        "res = chain_cover_letter.invoke({\n",
        "    \"resume_text\": pdf_path,\n",
        "    \"job_data\": json_res\n",
        "})\n",
        "\n",
        "# Save and display the cover letter\n",
        "cover_letter_text = res.content\n",
        "print(cover_letter_text)\n",
        "\n",
        "# Optional: Save to a file\n",
        "with open(\"generated_cover_letter.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "    file.write(cover_letter_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfK4ExyR5bK7",
        "outputId": "0b29aaa2-f907-4a7c-8b68-b387a0fbb555"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dear Hiring Manager,\n",
            "\n",
            "As a seasoned data professional with a passion for driving business growth through data-driven insights, I was thrilled to discover the Data Scientist/Engineer role at Greenspoon. With a strong foundation in data processing frameworks, cloud-based data platforms, and machine learning frameworks, I am confident that my skills and experience make me an ideal fit for this position. My resume, attached as Walter Kiptanui Rotich CV.pdf, provides a detailed account of my technical expertise and accomplishments.\n",
            "\n",
            "With over 2 years of experience in working with various data technologies, including Python, SQL, and data warehousing concepts, I possess a unique blend of technical and business acumen that enables me to architect and implement data solutions that drive business impact. My expertise in ETL technologies, such as Airbyte and Postman, has allowed me to streamline data pipelines and optimize data workflows. Additionally, my experience with data visualization tools like PowerBI and Tableau has enabled me to effectively communicate complex data insights to both technical and non-technical stakeholders.\n",
            "\n",
            "I am particularly drawn to this role at Greenspoon because of the opportunity to work closely with operational teams to transform vast data resources into strategic advantages. My experience in working with cross-functional teams has taught me the importance of collaboration and effective communication in driving business outcomes. I am excited about the prospect of applying my skills and expertise to help Greenspoon make smarter decisions about inventory, customer preferences, delivery optimization, and market trends.\n",
            "\n",
            "As a technical leader, I have a proven track record of developing and implementing data solutions that drive business growth and improvement. My experience with automation software, such as PowerAutomate and UIPath, has allowed me to automate manual processes and improve operational efficiency. I am confident that my technical expertise, combined with my business acumen and passion for data-driven decision making, make me a perfect fit for this role.\n",
            "\n",
            "Thank you for considering my application. I would welcome the opportunity to discuss my qualifications further and explore how my skills and experience align with the needs of Greenspoon. Please do not hesitate to contact me at your convenience to arrange a meeting or discussion.\n",
            "\n",
            "Sincerely,\n",
            "Walter Kiptanui Rotich\n"
          ]
        }
      ]
    }
  ]
}